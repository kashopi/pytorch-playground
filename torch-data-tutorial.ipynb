{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CUDA: False\n"
     ]
    }
   ],
   "source": [
    "enable_cuda = False\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "use_cuda = is_cuda_available and enable_cuda\n",
    "print(f\"Use CUDA: {use_cuda}\")\n",
    "if use_cuda:\n",
    "    torch.cuda.init()\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                       transform = transforms.Compose(\n",
    "                           [transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                       transform = transforms.Compose(\n",
    "                           [transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([6, 7, 8, 8, 0, 3, 9, 6, 2, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x183753126d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data[0][0].shape)\n",
    "plt.imshow(data[0][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0,\n",
    "                7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total +=1\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) # fc=fully connected\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) #Rectified Linear\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0807, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # lr=learning rate\n",
    "\n",
    "EPOCHS = 2\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data # data = featuresets and labels\n",
    "        net.zero_grad()\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.963\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if use_cuda:\n",
    "    X = X.cpu()\n",
    "    net = net.cpu()\n",
    "\n",
    "plt.imshow(X[3].view(28,28))\n",
    "plt.show()\n",
    "print(torch.argmax(net(X[3].view(-1, 28*28))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
