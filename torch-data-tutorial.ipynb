{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device: GeForce GTX 1050\n",
      "Use CUDA: False\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.init()\n",
    "enable_cuda = False\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "use_cuda = is_cuda_available and enable_cuda\n",
    "\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "print(f\"Use CUDA: {use_cuda}\")\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                       transform = transforms.Compose(\n",
    "                           [transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                       transform = transforms.Compose(\n",
    "                           [transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 3, 2, 7, 8, 1, 4, 6, 5, 4])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ae803ec780>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data[0][0].shape)\n",
    "plt.imshow(data[0][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0,\n",
    "                7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total +=1\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) # fc=fully connected\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) #Rectified Linear\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1705, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # lr=learning rate\n",
    "\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data # data = featuresets and labels\n",
    "        net.zero_grad()\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if use_cuda:\n",
    "    X = X.cpu()\n",
    "    net = net.cpu()\n",
    "\n",
    "plt.imshow(X[3].view(28,28))\n",
    "plt.show()\n",
    "print(torch.argmax(net(X[3].view(-1, 28*28))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
